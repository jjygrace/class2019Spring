{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 26 (Tues) nlp      2017130772 정준영"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - nlp : text를 다루는 것 / nltk : nlp와 가장 연관되는 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os : 외부에서 파일을 불러올 때 용이한 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'a man in the house' # untokenized string\n",
    "t = ['a', 'man', 'in', 'the', 'house'] # tokenized seqeuence of words as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - .Text 함수: type을 nltk 전용 variable로 바꾸어줌 - 전용 variable이 되면 nltk속 다양한 함수 사용가능한 이점이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: a man in the house...>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nltk.Text(t)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = nltk.Text(s.split())\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* open: full path를 적고 파일 open하는 함수 / encoding: 인코딩 지정 ex) utf8 = 한글 / A.read() : A를 불러오라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(os.getcwd()+r'/06_01.txt', encoding = 'utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1154507\n",
      "The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it\n"
     ]
    }
   ],
   "source": [
    "print(type(raw))\n",
    "print(len(raw))   # raw string의 총 길이\n",
    "print(raw[:200])  # 처음 부터 200 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - nltk.word_tokenize(...) : ... string을 쪼갬 / nltk에 속한 함수 / string을 쪼개어 list type으로 만들어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "257726\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))  # 몇 개의 token이 있는지(단어의 수와 비슷할 것)\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - .collocations() : 같이 나올 확률이 높은 것들을 함께 paired로 보여줌  ex) 이름과 성이 함께 보여짐 / text type에 사용 / token으로 쪼개어진 text type에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text[:10])\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - .concordance(찾을 단어, 가로로 보여질 character 수, 세로로 보여질 line 수) : 앞 뒤 문맥 볼 수 있음 / token으로 쪼개어진 text타입에 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 162 matches:\n",
      "and were more frequent in periods of great strain . In 1859 he was allowed to r\n",
      "ndency and of late she had read with great interest a book she got through Mr. \n",
      " the bosom of her family ... . And a great deal more ... . Quite excusable , si\n",
      "that you had heard that Dounia had a great deal to put up with in the Svidrigra\n",
      "g will she has . Dounia can endure a great deal and even in the most difficult \n",
      " that letter she reproached him with great heat and indignation for the basenes\n",
      "putation ; they had seen and known a great deal more than Mr. Svidrigailov had \n",
      "n other people ’ s . In my opinion a great deal , a very great deal of all this\n",
      " In my opinion a great deal , a very great deal of all this was unnecessary ; b\n",
      " . He is a very busy man and is in a great hurry to get to Petersburg , so that\n",
      " me that , though he is not a man of great education , he is clever and seems t\n",
      " very well . Of course , there is no great love either on his side , or on hers\n",
      "tted the matter has been arranged in great haste . Besides he is a man of great\n",
      "great haste . Besides he is a man of great prudence and he will see , to be sur\n",
      "d that she is ready to put up with a great deal , if only their future relation\n",
      " off for Petersburg , where he has a great deal of business , and he wants to o\n",
      "a or I breathed a word to him of the great hopes we have of his helping us to p\n",
      "ites that ‘ Dounia can put up with a great deal. ’ I know that very well . I kn\n",
      "at , that ‘ Dounia can put up with a great deal. ’ If she could put up with Mr.\n",
      "it , she certainly can put up with a great deal . And now mother and she have t\n",
      "e young , and she was walking in the great heat bareheaded and with no parasol \n",
      "f the skirt , close to the waist : a great piece was rent and hanging loose . A\n",
      "ts or conversations . He worked with great intensity without sparing himself , \n",
      " uproarious and was reputed to be of great physical strength . One night , when\n",
      ". His legs felt suddenly heavy and a great drowsiness came upon him . He turned\n"
     ]
    }
   ],
   "source": [
    "text.concordance('great', 79, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - nltk.FreqDist() : raw한 string을 입력으로 넣어도 무엇이 가장 빈번하게 나오는지 알 수 있는 함수\n",
    "#### - A.most_common(...): A에서 가장 common한 것 ... 개를 보여줌, tuple의 형태로 요소와 그 빈도를 함께 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* comment out 단축키 : ctrl + / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Moby Dick by Herman Melville 1851]\n",
      "\n",
      "\n",
      "ETYMOLOGY.\n",
      "\n",
      "(Supplied by a Late Consumptive Usher to a Grammar School)\n",
      "\n",
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.  He was\n",
      "[(' ', 198098), ('e', 115855), ('t', 85539), ('a', 75266), ('o', 68338), ('n', 64431), ('s', 62022), ('i', 61891), ('h', 61434), ('r', 51311), ('l', 41893), ('d', 37468), ('u', 26457), ('\\r', 22924), ('\\n', 22924), ('m', 22525), ('c', 21360), ('w', 20917), ('g', 20180), ('f', 20029), (',', 19229), ('y', 16542), ('p', 16207), ('b', 15451), ('v', 8427), ('k', 7882), ('.', 7558), ('-', 5984), (';', 4173), ('I', 3543), ('\"', 3071), (\"'\", 2922), ('A', 2650), ('T', 2457), ('S', 2209), ('!', 1767), ('H', 1462), ('B', 1426), ('W', 1305), ('E', 1237), ('q', 1234), ('N', 1186), ('C', 1147), ('P', 1048), ('x', 1007), ('?', 1004), ('O', 988), ('L', 900), ('j', 829), ('R', 823)]\n"
     ]
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')   # 라이브러리 안에 있는 예제 데이터 모비딕 텍스트\n",
    "print(raw[:200])\n",
    "fdist = nltk.FreqDist(raw)\n",
    "print(fdist.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [ ch.lower() / for ch / in raw / if ch.isalpha() ] : raw 속에서 for loop를 돌면서 ch로 값을 받는데, 그 ch가 알파벳인가?(if구문) 알파벳이면 리스트로 만드는데, lower case(소문자)로 받아와라   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', 105049), ('t', 80836), ('a', 74052), ('o', 72238), ('n', 63157)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 't', 'a', 'o', 'n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())  # raw파일의 길이만큼 for loop 돌아감\n",
    "print(fdist.most_common(5))   # 빈도수 상위 5개\n",
    "[char for (char, count) in fdist.most_common(5)]  # 빈도수 상위 5개 도출한 것에서 for loop 5번 돌면서 character만 받아내 list로 만들어라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zymosis',\n",
       " 'zymosterol',\n",
       " 'zymosthenic',\n",
       " 'zymotechnic',\n",
       " 'zymotechnical',\n",
       " 'zymotechnics',\n",
       " 'zymotechny',\n",
       " 'zymotic',\n",
       " 'zymotically',\n",
       " 'zymotize',\n",
       " 'zymotoxic',\n",
       " 'zymurgy',\n",
       " 'Zyrenian',\n",
       " 'Zyrian',\n",
       " 'Zyryan',\n",
       " 'zythem',\n",
       " 'Zythia',\n",
       " 'zythum',\n",
       " 'Zyzomys']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.words.words('en')[-20:-1]   # 가장 마지막 요소부터 마지막에서 앞으로 19번째까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.words.words('en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'What to some people, then, may seem natural in their interactions is a result of what Butler James calls a set of repearted acts. Expanded and updated-still absolutely the best for teaching and learing about discourse analysis. Miriam Meyerhoff, Professor of Linguistics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "print(type(a))\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'to', 'some', 'people', ',', 'then', ',', 'may', 'seem', 'natural', 'in', 'their', 'interactions', 'is', 'a', 'result', 'of', 'what', 'Butler', 'James', 'calls', 'a', 'set', 'of', 'repearted', 'acts', '.', 'Expanded', 'and', 'updated-still', 'absolutely', 'the', 'best', 'for', 'teaching', 'and', 'learing', 'about', 'discourse', 'analysis', '.', 'Miriam', 'Meyerhoff', ',', 'Professor', 'of', 'Linguistics']\n"
     ]
    }
   ],
   "source": [
    "tokens_a = nltk.word_tokenize(a)\n",
    "print(tokens_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: What to some people , then , may...>\n",
      "<class 'nltk.text.Text'>\n"
     ]
    }
   ],
   "source": [
    "text_a = nltk.Text(tokens_a)\n",
    "print(text_a)\n",
    "print(type(text_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('E', 27), ('A', 23), ('T', 21), ('S', 20), ('I', 15)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E', 'A', 'T', 'S', 'I']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_a = nltk.FreqDist(i.upper() for i in a if i.isalpha())\n",
    "print(fdist_a.most_common(5))\n",
    "[char for (char, num) in fdist_a.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'list'>\n",
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar', 'School', ')', 'The', 'pale', 'Usher', '--', 'threadbare', 'in', 'coat', ',', 'heart', ',', 'body', ',', 'and', 'brain', ';', 'I', 'see', 'him', 'now', '.', 'He', 'was', 'ever', 'dusting', 'his', 'old', 'lexicons', 'and']\n",
      "<class 'nltk.text.Text'>\n"
     ]
    }
   ],
   "source": [
    "print(type(b))\n",
    "tokens_b = nltk.word_tokenize(b)\n",
    "print(type(tokens_b))\n",
    "print(tokens_b[:50])\n",
    "text_b = nltk.Text(tokens_b)\n",
    "print(type(text_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 50 of 463 matches:\n",
      "ng at the stern of the ship , they cut off his hea\n",
      " they should run their ship upon them . '' -- SCHO\n",
      "be , wind N.E . in the ship called The Jonas-in-th\n",
      "SHIPWRECK OF THE WHALE SHIP ESSEX OF NANTUCKET , W\n",
      "t the whites saw their ship in bloody possession o\n",
      " I quietly take to the ship . There is nothing sur\n",
      "told that you and your ship were now out of sight \n",
      "e ; the half-foundered ship weltering there with i\n",
      "s trying his hand at a ship under full sail , but \n",
      " ' voyage , and a full ship . Hurrah , boys ; now \n",
      "; then laying a bit of ship biscuit on top and app\n",
      " and harpooneers , and ship keepers ; a brown and \n",
      "e boats ' crews OF THE SHIP ELIZA Who were towed o\n",
      "ose used in mounting a ship from a boat at sea . T\n",
      "wever convenient for a ship , these joints in the \n",
      "representing a gallant ship beating against a terr\n",
      "t of radiance upon the ship 's tossed deck , somet\n",
      "n fell . `` Ah , noble ship , '' the angel seemed \n",
      ", beat on , thou noble ship , and bear a hardy hel\n",
      "s in the likeness of a ship 's bluff bows , and th\n",
      ". Yes , the world 's a ship on its passage out , a\n",
      "tolling of a bell in a ship that is foundering at \n",
      "Him . He thinks that a ship made by men will carry\n",
      "of Joppa , and seeks a ship that 's bound for Tars\n",
      " he finds the Tarshish ship receiving the last ite\n",
      "the wharf to which the ship is moored , offering f\n",
      "seek a passage in this ship to Tarshish ; how soon\n",
      "nk , too , beneath the ship 's water-line , Jonah \n",
      "onah 's room ; and the ship , heeling over towards\n",
      "of tide has come ; the ship casts off her cables ;\n",
      "ed wharf the uncheered ship for Tarshish , all car\n",
      ", glides to sea . That ship , my friends , was the\n",
      "l storm comes on , the ship is like to break . But\n",
      " into the sides of the ship -- a berth in the cabi\n",
      "ve thus leaps into the ship , and finding no speed\n",
      "ther means to save the ship . But all in vain ; th\n",
      " and his God by taking ship at Joppa . But God is \n",
      "support him , when the ship of this base treachero\n",
      "d youth . A Sag Harbor ship visited his father 's \n",
      "istian lands . But the ship , having her full comp\n",
      "it , which he knew the ship must pass through when\n",
      "in hand ; and when the ship was gliding by , like \n",
      "ny me to that island , ship aboard the same vessel\n",
      "or . The owners of his ship , it seems , had lent \n",
      "certain grand merchant ship once touched at Rokovo\n",
      " -- being Captain of a ship -- as having plain pre\n",
      "s , mixed with pounded ship biscuit , and salted p\n",
      "ty . '' CHAPTER 16 The Ship . In bed we concocted \n",
      "t the selection of the ship should rest wholly wit\n",
      "sel I must immediately ship myself , for the prese\n"
     ]
    }
   ],
   "source": [
    "text_b.concordance('ship', 50, 50)   # tokenize후 text 타입으로 바꾸어야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sperm Whale; Moby Dick; White Whale; old man; Captain Ahab; sperm\n",
      "whale; Right Whale; Captain Peleg; Mr. Starbuck; New Bedford; Cape\n",
      "Horn; 'ye see; cried Ahab; years ago; lower jaw; white whale; Mrs.\n",
      "Hussey; chief mate; never mind; Father Mapple\n"
     ]
    }
   ],
   "source": [
    "text_b.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 198098), ('e', 115855), ('t', 85539), ('a', 75266), ('o', 68338), ('n', 64431), ('s', 62022), ('i', 61891), ('h', 61434), ('r', 51311)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ', 'e', 't', 'a', 'o']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = nltk.FreqDist(b)\n",
    "print(c.most_common(10))\n",
    "[char for (char, num) in c.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
