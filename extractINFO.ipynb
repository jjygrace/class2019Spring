{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nlp추가 사항  2017130772 정준영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPOS tag list:\\n\\nCC\\tcoordinating conjunction\\nCD\\tcardinal digit\\nDT\\tdeterminer\\nEX\\texistential there (like: \"there is\" ... think of it like \"there exists\")\\nFW\\tforeign word\\nIN\\tpreposition/subordinating conjunction\\nJJ\\tadjective\\t\\'big\\'\\nJJR\\tadjective, comparative\\t\\'bigger\\'\\nJJS\\tadjective, superlative\\t\\'biggest\\'\\nLS\\tlist marker\\t1)\\nMD\\tmodal\\tcould, will\\nNN\\tnoun, singular \\'desk\\'\\nNNS\\tnoun plural\\t\\'desks\\'\\nNNP\\tproper noun, singular\\t\\'Harrison\\'\\nNNPS\\tproper noun, plural\\t\\'Americans\\'\\nPDT\\tpredeterminer\\t\\'all the kids\\'\\nPOS\\tpossessive ending\\tparent\\'s\\nPRP\\tpersonal pronoun\\tI, he, she\\nPRP$\\tpossessive pronoun\\tmy, his, hers\\nRB\\tadverb\\tvery, silently,\\nRBR\\tadverb, comparative\\tbetter\\nRBS\\tadverb, superlative\\tbest\\nRP\\tparticle\\tgive up\\nTO\\tto\\tgo \\'to\\' the store.\\nUH\\tinterjection\\terrrrrrrrm\\nVB\\tverb, base form\\ttake\\nVBD\\tverb, past tense\\ttook\\nVBG\\tverb, gerund/present participle\\ttaking\\nVBN\\tverb, past participle\\ttaken\\nVBP\\tverb, sing. present, non-3d\\ttake\\nVBZ\\tverb, 3rd person sing. present\\ttakes\\nWDT\\twh-determiner\\twhich\\nWP\\twh-pronoun\\twho, what\\nWP$\\tpossessive wh-pronoun\\twhose\\nWRB\\twh-abverb\\twhere, when\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "POS(품사) tag list: \n",
    "\n",
    "CC\tcoordinating conjunction\n",
    "CD\tcardinal digit\n",
    "DT\tdeterminer\n",
    "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "FW\tforeign word\n",
    "IN\tpreposition/subordinating conjunction\n",
    "JJ\tadjective\t'big'\n",
    "JJR\tadjective, comparative\t'bigger'\n",
    "JJS\tadjective, superlative\t'biggest'\n",
    "LS\tlist marker\t1)\n",
    "MD\tmodal\tcould, will\n",
    "NN\tnoun, singular 'desk'\n",
    "NNS\tnoun plural\t'desks'\n",
    "NNP\tproper noun, singular\t'Harrison'\n",
    "NNPS\tproper noun, plural\t'Americans'\n",
    "PDT\tpredeterminer\t'all the kids'\n",
    "POS\tpossessive ending\tparent's\n",
    "PRP\tpersonal pronoun\tI, he, she\n",
    "PRP$\tpossessive pronoun\tmy, his, hers\n",
    "RB\tadverb\tvery, silently,\n",
    "RBR\tadverb, comparative\tbetter\n",
    "RBS\tadverb, superlative\tbest\n",
    "RP\tparticle\tgive up\n",
    "TO\tto\tgo 'to' the store.\n",
    "UH\tinterjection\terrrrrrrrm\n",
    "VB\tverb, base form\ttake\n",
    "VBD\tverb, past tense\ttook\n",
    "VBG\tverb, gerund/present participle\ttaking\n",
    "VBN\tverb, past participle\ttaken\n",
    "VBP\tverb, sing. present, non-3d\ttake\n",
    "VBZ\tverb, 3rd person sing. present\ttakes\n",
    "WDT\twh-determiner\twhich\n",
    "WP\twh-pronoun\twho, what\n",
    "WP$\tpossessive wh-pronoun\twhose\n",
    "WRB\twh-abverb\twhere, when\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'Jhon', 'from', 'America', 'and', 'would', 'like', 'to', 'go', 'to', 'Starbuck']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sent = \"I am Jhon from America and would like to go to Starbuck\"\n",
    "token = nltk.word_tokenize(sent)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('am', 'VBP'), ('Jhon', 'RB'), ('from', 'IN'), ('America', 'NNP'), ('and', 'CC'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('go', 'VB'), ('to', 'TO'), ('Starbuck', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "pos = nltk.pos_tag(token)  # nltk.pos_tag : tokenize 된 것들의 품사가 무엇인지 각각 다 찾는 함수 / tuple로 결과가 나오는 이유: 정보 수정하지 못하게끔.(정보왜곡보호)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nltk.ne_chunk 함수: named entity 찾는 함수 / NE : named entity의 줄임말 = 문장 속에서 중요한 요소만 뽑아서 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* named entity와 intention이 중요함: 무엇을(NE) 어떻게(intention) 할 것인가.\n",
    "* rule-based : 모든 가능성을 미리 set해놓음. 틀릴 가능성은 없음. 그러나 일치하지 않으면 아웃풋 없음 / machine-learnig : 일치하지 않아도 아웃풋을 주기는 함. 그러나 틀릴가능성 있음(확률에 기반하기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  Jhon/RB\n",
      "  from/IN\n",
      "  (GPE America/NNP)\n",
      "  and/CC\n",
      "  would/MD\n",
      "  like/VB\n",
      "  to/TO\n",
      "  go/VB\n",
      "  to/TO\n",
      "  (PERSON Starbuck/NNP))\n"
     ]
    }
   ],
   "source": [
    "NE = nltk.ne_chunk(pos)\n",
    "print(NE)\n",
    "# common Entity types: ORGANIZATION, PERSON, LOCATION, DATE, TIME, MONEY, and GPE (geo-political entity) : 중요한 요소라고 고려되는 타입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['James', 'came', 'from', 'California', 'and', 'he', 'loves', 'to', 'watch', 'TV', 'and', 'eat', 'potato', 'chips']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sent = \"James came from California and he loves to watch TV and eat potato chips \"\n",
    "tokens = nltk.word_tokenize(sent)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('James', 'NNP'), ('came', 'VBD'), ('from', 'IN'), ('California', 'NNP'), ('and', 'CC'), ('he', 'PRP'), ('loves', 'VBZ'), ('to', 'TO'), ('watch', 'VB'), ('TV', 'NN'), ('and', 'CC'), ('eat', 'NN'), ('potato', 'NN'), ('chips', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "pos_2 = nltk.pos_tag(tokens)\n",
    "print(pos_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON James/NNP)\n",
      "  came/VBD\n",
      "  from/IN\n",
      "  (GPE California/NNP)\n",
      "  and/CC\n",
      "  he/PRP\n",
      "  loves/VBZ\n",
      "  to/TO\n",
      "  watch/VB\n",
      "  TV/NN\n",
      "  and/CC\n",
      "  eat/NN\n",
      "  potato/NN\n",
      "  chips/NNS)\n"
     ]
    }
   ],
   "source": [
    "NE = nltk.ne_chunk(pos_2)\n",
    "print(NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jane', 'and', 'Mary', 'booked', 'flight', 'tickets', 'for', 'New', 'York', 'at', '10:30', 'pm', ',', 'departing', 'from', 'Incheon', 'airport']\n"
     ]
    }
   ],
   "source": [
    "sent_2 = \"Jane and Mary booked flight tickets for New York at 10:30 pm, departing from Incheon airport\"\n",
    "tokens_2 = nltk.word_tokenize(sent_2)\n",
    "print(tokens_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jane', 'NNP'), ('and', 'CC'), ('Mary', 'NNP'), ('booked', 'VBD'), ('flight', 'NN'), ('tickets', 'NNS'), ('for', 'IN'), ('New', 'NNP'), ('York', 'NNP'), ('at', 'IN'), ('10:30', 'CD'), ('pm', 'NN'), (',', ','), ('departing', 'VBG'), ('from', 'IN'), ('Incheon', 'NNP'), ('airport', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "pos_3 = nltk.pos_tag(tokens_2)\n",
    "print(pos_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Jane/NNP)\n",
      "  and/CC\n",
      "  (PERSON Mary/NNP)\n",
      "  booked/VBD\n",
      "  flight/NN\n",
      "  tickets/NNS\n",
      "  for/IN\n",
      "  (GPE New/NNP York/NNP)\n",
      "  at/IN\n",
      "  10:30/CD\n",
      "  pm/NN\n",
      "  ,/,\n",
      "  departing/VBG\n",
      "  from/IN\n",
      "  (GPE Incheon/NNP)\n",
      "  airport/NN)\n"
     ]
    }
   ],
   "source": [
    "NE_2 = nltk.ne_chunk(pos_3)\n",
    "print(NE_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
